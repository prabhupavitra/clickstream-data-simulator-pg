{
  "pipelines": "数据管道",
  "basic": "基本信息",
  "id": "ID",
  "name": "名称",
  "desc": "描述",
  "status": "状态",
  "creationMethod": "创建方法",
  "lastEditDate": "上次编辑日期",
  "tagDesc": "这些标签将传播到该数据管道中的所有资源",
  "valid": {
    "nameEmpty": "请输入数据管道名称。",
    "regionEmpty": "请选择亚马逊云科技区域（region)。",
    "vpcEmpty": "请选择 VPC。",
    "sdkEmpty": "请指定您将使用哪种类型的 SDK 向该数据管道发送数据",
    "s3BucketEmpty": "请选择 Amazon S3 存储桶",
    "s3BucketNoExist": "Amazon S3 存储桶不存在",
    "publicSubnetEmpty": "请为采集终端节点选择至少 2 个跨可用区的公共子网",
    "privateSubnetEmpty": "请为采集端点选择至少 2 个跨可用区的私有子网",
    "privateSubnetDiffWithPublicError": "私有子网必须位于与公有子网相同的可用区中。",
    "domainNameEmpty": "请输入域名",
    "domainNameInvalid": "域名格式无效",
    "certificateEmpty": "请选择 SSL 证书",
    "dataProcessorIntervalError": "数据处理间隔不能低于 6 分钟",
    "dataProcessorIntervalCronError": "Cron表达式的格式如下：Cron(分 时 每月的第N天 月 星期 年)",
    "acknowledgeHTTPSecurity": "请单击 “确认” 按钮继续。",
    "sinkIntervalError": "间隔值必须大于 {{min}} 且小于 {{max}}",
    "sinkSizeError": "大小值必须大于 {{min}} 且小于 {{max}}",
    "minCapacityError": "最小容量必须为整数且大于或等于 1",
    "maxCapacityError": "最大容量必须为整数且大于最小容量",
    "warmPoolError": "Warm pool必须是整数且小于最大容量",
    "corsFormatError": "CORS 域名格式错误",
    "secretEmptyError": "请选择一个密钥",
    "mskEmptyError": "请选择 MSK 集群",
    "topicFormatError": "主题格式错误",
    "kafkaBrokerEmptyError": "请输入以逗号分隔的 Kafka 代理。例如，代理 1:端口，代理 2:端口",
    "kafkaBrokerFormatError": "Kafka 代理用逗号分隔。例如，代理 1:端口，代理 2:端口",
    "kafkaSGEmptyError": "请选择安全组",
    "bufferS3PrefixError": "S3 前缀长度必须小于 1024 个字符。",
    "bufferS3SizeError": "缓冲区大小数字必须介于 1 到 50 之间。",
    "bufferS3IntervalError": "缓冲间隔数必须介于 60 和 3600 之间。",
    "bufferKDSModeEmptyError": "请选择模式",
    "bufferKDSShardNumError": "分片数必须介于 1 和 10000 之间",
    "redshiftServerlessVpcEmptyError": "请选择一个 vpc",
    "redshiftServerlessSGEmptyError": "请选择安全组",
    "redshiftServerlessSubnetEmptyError": "请选择子网",
    "redshiftServerlessSubnetInvalidError": "请选择位于至少 2 个不同可用区的至少 3 个子网",
    "redshiftProvisionedClusterEmptyError": "请选择群集",
    "redshiftProvisionedDBUserEmptyError": "请输入数据库用户。",
    "redshiftProvisionedDBUserFormatError": "数据库用户格式错误",
    "emailInvalid": "电子邮件无效。",
    "stackRollbackFailed": "某些堆栈处于 ROLLBACK_FAILED 状态，无法更新。",
    "transformPluginEmptyError": "使用第三方 SDK 时需选择转换插件。",
    "tagsKeyValueEmpty": "标签键和值不能为空。",
    "quickSightUserEmptyError": "请选择QuickSight管理员用户"
  },
  "create": {
    "basicInfo": "基本配置",
    "configIngestion": "数据摄取",
    "dataProcessor": "数据处理和建模",
    "reporting": "报表",
    "reviewLaunch": "查看并启动",
    "selectFile": "选择映射文件",
    "selectFileDesc": "请确保使用提供的模板",
    "selectFileConstraint": "最大文件大小为 25MB",
    "chooseFile": "选择文件",
    "fileSize": "文件大小（以字节为单位）上次修改日期",
    "usingUIAlert": "此处未指定的任何字段都将作为参数添加到 event_param 字段中。",
    "usingUIInfo": "您最多可以再添加 42 个键。",
    "usingUIAdd": "添加新映射",
    "dataKey": "你的数据键",
    "dataValue": "数据值",
    "enterKey": "输入键",
    "enterValue": "输入值",
    "noItems": "没有与资源关联的项目。",
    "s3Assets": "数据位置",
    "s3AssetsDesc": "选择 Amazon S3 位置来存储该项目的原始数据和经过处理的数据。",
    "selectS3": "选择 Amazon S3 存储桶",
    "sinkMaxInterval": "最大数据下沉间隔",
    "sinkMaxIntervalDesc": "指定在流式传输到 Amazon S3 之前应缓冲记录的最大时间长度（以秒为单位）",
    "sinkBatchSize": "数据批次大小",
    "sinkBatchSizeDesc": "单批中可交付的最大记录数",
    "kds": {
      "kdsSettings": "Amazon Kinesis Data Streams 设置",
      "kdsSettingsDesc": "该解决方案将根据您的规格为您创建 KDS。",
      "shardNum": "分片数",
      "shardNumDesc": "指定 Kinesis Data Streams的分片数量。每个分片每秒最多可以有 1,000 条记录，总数据写入速率为每秒 1MB。",
      "enableAS": "启用自动扩缩",
      "enableASDesc": "如果要为 KDS 启用自动扩缩，请选择 “是”",
      "maxShard": "最大分片数",
      "maxShardDesc": "指定最大分片数。",
      "provisionMode": "模式",
      "provisionModeDesc": "如果您想为 KDS 启用自动扩缩，请选择 “按需” 模式",
      "selectMode": "选择模式",
      "onDemand": "按需",
      "provisioned": "预置"
    },
    "msk": {
      "mskCluster": "连接到 Apache Kafka 集群",
      "mskClusterDesc": "您可以选择使用 Amazon Managed Streaming for Apache Kafka (Amazon MSK) 集群或自托管 Kafka 集群。",
      "select": "Amazon MSK",
      "topic": "主题 （topic)",
      "topicDesc": "默认情况下，该解决方案将创建一个带有 “项目 ID” 的主题（topic)，您可以对其进行自定义。",
      "enterTopicName": "输入自定义主题（topic)名称",
      "manual": "托管",
      "brokerLink": "Broker 链接",
      "brokerLinkDesc": "输入您要连接的集群的连接 URL。",
      "brokerLindPlaceHolder": "输入连接 URL",
      "manualTopicDesc": "请指定存储数据的主题",
      "selectMSK": "请选择 MSK 集群",
      "createMSK": "创建快速启动集群",
      "createMSKDesc": "该解决方案创建了一个小型 MSK 集群（2vCPU，8RAM）作为启动程序，适用于测试目的",
      "existingMSK": "选择现有集群",
      "existingMSKDesc": "该解决方案与同一 VPC 中的 MSK 集群建立连接"
    },
    "s3": {
      "bufferSize": "缓冲区大小",
      "bufferSizeDesc": "在发送到 Amazon S3 之前指定要缓冲的数据大小。缓冲区大小越大，成本可能越低，延迟越高，缓冲区大小越小，交付速度越快，成本越高。最小：1 MiB，最大：50 MiB",
      "bufferInterval": "缓冲间隔",
      "bufferIntervalDesc": "间隔越高，收集数据的时间越长，数据的大小可能越大。较低的间隔发送数据的频率更高，在查看较短的数据活动周期时可能更有优势。最小：60，最大：3600"
    },
    "pipeline": "数据管道",
    "name": "名称",
    "nameDesc": "请给出一个对您的组织有意义的数据管道名称。",
    "nameConstraint": "名称长度可达 200 个字符。有效字符为 a-z、A-Z、0-9、。（句点）、_（下划线）和-（连字符）。",
    "desc": "描述",
    "descPlaceholder": "你的描述",
    "awsRegion": "亚马逊云科技区域（region)",
    "awsRegionDesc": "指定要将管道部署到的区域 (region)。",
    "awsRegionPlaceholder": "选择 AWS 区域",
    "vpc": "VPC",
    "vpcDesc": "指定要将管道部署到的 VPC。",
    "vpcPlaceholder": "选择一个 VPC",
    "dataSDK": "数据收集 SDK",
    "dataSDKDesc": "指定您计划用于向此管道发送数据的 SDK 类型。请注意，Clickstream SDK 指的是此解决方案提供的 SDK；Third-Party SDK 是指其他非本方案提供的 SDK。",
    "dataSDKPlaceholder": "指定 SDK 类型",
    "selectSDKPlaceholder": "指定 SDK 类型",
    "itemSelection": "项目选择",
    "lastEdit": "上次编辑",
    "loading": "正在加载资源",
    "noPlugin": "没有插件",
    "noPluginDisplay": "没有插件可显示。",
    "findPlugin": "查找插件",
    "selectEnrich": "选择要启用或禁用的数据富化插件",
    "enrichPlugins": "数据富化插件",
    "code": "代码",
    "config": "配置",
    "enableEdp": "启用自定义终端节点",
    "enableEdpDesc": "该解决方案提供自动生成的 URL 作为采集端点，但您也可以使用自定义终端节点。请注意，主机名必须在亚马逊 Route53 服务中注册",
    "edpSettings": "摄取端点设置",
    "edpSettingsDesc": "该解决方案将启动网络服务作为采集端点，以收集从 SDK 发送的数据。",
    "networkType": "网络类型",
    "networkTypeGeneral": "标准",
    "networkTypeGeneralDesc": "子网包含公有子网和私有子网",
    "networkTypePrivate": "私有",
    "networkTypePrivateDesc": "子网仅包含私有子网",
    "enableHttps": "启用HTTPS",
    "domainName": "域名",
    "domainNameDesc": "为您的采集终端节点指定域名，该解决方案将自动在 Route53 中为您创建条目。",
    "domainNameR53Placeholder": "选择托管区域",
    "hostedZone": "托管区域",
    "requestPath": "请求路径",
    "requestPathDesc": "采集端点收集数据的默认路径是 “/collect”，你可以在下面的文本框中将其修改。",
    "requestPlaceholder": "collect",
    "cors": "跨源资源共享 (CORS)",
    "corsDesc": "CORS设置允许浏览器发送来自特定域的请求。如果您正在从web应用程序收集点击流数据，请在下面的文本框中输入允许的域。",
    "corsPlaceholder": "http://collect.example.com,https://data.example.com",
    "ingestionCapacity": "摄取容量",
    "ingestionCapacityDesc": "单个摄取计算单元 (ICU) 代表可计费的计算和内存单元、大约 8 GB 的内存和 2 个 vCPU。1 个 ICU 通常每秒可以支持 4000 到 6000 个请求。",
    "minSize": "最小容量",
    "maxSize": "最大容量",
    "warmPool": "暖池",
    "ingestionCapacityFargateDesc": "将创建ECS任务来处理请求和获取数据，每个任务使用大约 512 MiB的内存和 0.25 个 vCPU，一个任务通常每秒可以支持大约100个请求。",
    "ingestionTypeFargateDesc": "用于少量、批量、突发流量或者维护预算为零的工作负载。",
    "ingestionTypeEC2Desc": "用于具有稳定流量需求的大型工作负载。",
    "subnet": "子网",
    "subnetDesc": "指定您希望采集端点在哪些子网中运行",
    "subnetPlaceholder": "选择子网",
    "dataSink": "数据宿(Data sink)设置",
    "dataSinkDesc": "配置如何收集数据以供下游使用。",
    "bufferType": "数据宿(Data sink)类型",
    "bufferTypeDesc": "选择要使用的数据宿(Data sink)类型。",
    "bufferS3": "Amazon S3",
    "bufferS3Desc": "数据缓存在采集服务器内存中，然后保存到 S3 存储桶中，如果您不需要实时数据流，请使用此选项。",
    "bufferMSK": "Apache Kafka",
    "bufferMSKDesc": "数据将流式传输到 Kafka 集群中的主题中以供实时使用，Kafka 连接器将定期读取数据并将其存储到 S3 存储桶中。",
    "bufferKDS": "Amazon Kinesis Data Streams (KDS)",
    "bufferKDSDesc": "数据将流式传输到 Amazon KDS 以供实时使用，而 lambda 程序将定期读取数据并将其存储到 S3 存储桶中。",
    "kafkaRequirements": "您的 kafka 集群必须满足文档中强调的要求。",
    "mskSecurityGroupDesc": "此 VPC 安全组定义了哪些子网和 IP 范围可以访问 Kafka 集群。",
    "enableModeling": "启用数据建模",
    "enableModelingDesc": "该解决方案附带用于网页和移动端应用程序事件分析的数据模型，可在报告工具中创建开箱即用的仪表板，也可以根据您的需求对其进行自定义报表。要启用数据模型，您需要提供事件数据结构和解决方案的数据模型之间的映射。如果您选择不使用我们的数据模型，则原始事件数据将存储在指定的数据桶中。",
    "enableDataModel": "启用数据模型",
    "modelCreationMethod": "创建方法",
    "modelCreationMethodDesc": "选择创建数据映射的方法",
    "uploadFile": "上传映射文件",
    "uploadFileDesc": "请使用模板定义映射关系",
    "usingUI": "使用用户界面",
    "usingUIDesc": "为用户界面上的每个字段定义映射关系",
    "engineSetting": "引擎设置",
    "engineSettingDesc": "选择对数据进行建模的引擎并配置数据建模作业的运行方式",
    "engineRedshift": "Redshift",
    "engineRedshiftDesc": "数据将加载到 Redshift，建模工作将由 Redshift 运行",
    "engineAthena": "Athena",
    "engineAthenaDesc": "数据将存储在 S3 中，建模工作将由 Athena 运行",
    "engineRedshiftCluster": "Redshift 集群",
    "engineRedshiftClusterDesc": "选择 Redshift 集群作为此管道的数据建模引擎 ",
    "engineRedshiftClusterPlaceholder": "查找集群",
    "engineDataRange": "数据范围",
    "engineDataRangeDesc": "指定要加载到 Redshift 进行数据建模的数据的时间范围，Redshift 将自动删除超出指定范围的数据。但是所有数据仍然存在于 S3 当中，可供你使用 Redshift Specturm 或 Athena 进行查询。",
    "engineDuration": "持续时间",
    "engineDurationPlaceholder": "输入持续时间",
    "engineUnitOfTime": "时间单位",
    "engineDataPartition": "数据分区",
    "engineDataPartitionDesc": "在 Redshift 中指定要如何对数据进行分区。",
    "engineDataPartitionAlert": "此设置将影响您的业务的控制面板和指标，请仔细选择。",
    "engineBaseIngestionTime": "根据摄取时间进行分区",
    "engineBaseIngestionTimeDesc": "事件数据将根据摄取端点接收的时间进行分区。",
    "reportSettings": "报告设置",
    "reportSettingsDesc": "为解决方案指定 QuickSight 设置以创建分析报告",
    "createSampleQuickSight": "在 QuickSight 中创建示例报表",
    "createSampleQuickSightDesc": "启用此功能将允许解决方案在您的 QuickSight 帐户中创建示例仪表板（<learnmore_anchor>了解更多</learnmore_anchor>）。如果您的 AWS 账户尚未注册 QuickSight，系统将要求您按照本<guide_anchor>指南</guide_anchor>先注册。",
    "quickSightNotSub": "您的账户中没有订阅 QuickSight",
    "quickSightNotSubDesc1": "该解决方案检测到您的账户尚未订阅 QuickSight，请 ",
    "quickSightNotSubDesc2": "。请注意，会有额外费用产生。",
    "quickSightNotEnterprise": "您的账户中的 QuickSight 版本不是企业版",
    "quickSightNotEnterpriseDesc": "解决方案控制面板需要 QuickSight Enterprise，你可以在 QuickSight 管理控制台中升级版本。",
    "quickSightSubscription": "订阅",
    "quickSIghtPlaceholder": "选择 quicksight 用户",
    "quickSightUser": "QuickSight 用户",
    "quickSightUserDesc": "为解决方案选择一个QuickSight管理员用户以创建数据集和分析。",
    "ingestSettings": "摄取设置",
    "clusterSize": "集群大小",
    "topic": "主题",
    "modelSettings": "数据建模设置",
    "modelSettingsDesc": "数据建模设置描述",
    "modelEngine": "建模引擎",
    "enableETL": "启用数据处理 ",
    "enableETLDesc1": "此解决方案提供了预置的数据模式 ",
    "enableETLDesc2": " 来对从网页端和移动端应用程序发送的原始事件数据进行建模，从而可以生成开箱即用的仪表板，让您轻松构建业务特定分析。要使用该方案的数据模式，您需要启用数据处理将原始事件数据转换为我们的数据模型。如果您选择其他方式，您的数据将以原始格式保存在 S3 中，并且不会生成任何预置报表。",
    "transform": "转换",
    "transformDesc1": "由于您已选择使用第三方 SDK，因此需要提供自定义插件以将原始数据转换为解决方案数据模型 ",
    "transformDesc2": " 启用扩充和数据建模",
    "publicSubnet": "公共子网",
    "publicSubnetDesc": "请选择公共子网。您需要在两个可用区 (AZ) 上至少有两个公有子网。",
    "privateSubnet": "私有子网",
    "privateSubnetDesc": "请选择私有子网。您需要在两个可用区 (AZ) 上至少有两个私有子网。",
    "workgroup": "工作组",
    "workgroupDesc": "选择一个工作组来执行建模和查询",
    "findWorkGroup": "找一个工作组",
    "duration": "持续时间",
    "executionParam": "执行参数",
    "executionParamDesc": "配置数据处理作业的关键行为。",
    "processInterval": "数据处理间隔",
    "processIntervalDesc": "指定数据批处理的时间间隔。请确保指定的间隔长于摄取缓冲区间隔。",
    "eventFreshness": "事件数据新鲜度",
    "eventFreshnessDesc": "事件数据新鲜度是指解决方案将忽略事件数据的期限。例如，如果您为此参数指定 3 天，则解决方案将忽略在客户端在3天前触发的任何事件。",
    "analyticEngine": "数据建模设置",
    "analyticEngineDesc": "选择分析引擎来建模和查询您的点击流数据。",
    "redshift": "Redshift",
    "redshiftDesc": "数据将加载到亚马逊 Redshift 数据仓库以进行进一步的建模和查询。",
    "redshiftCluster": "Redshift 集群",
    "redshiftClusterDesc": "选择 redshift 集群作为此管道的数据建模引擎。",
    "redshiftBaseCapacity": "基础 RPU",
    "redshiftBaseCapacityDesc": "设置用于处理工作负载的 Redshift 处理单元 (RPU) 中的基本容量。一个 RPU 提供 16 GB 的内存。",
    "redshiftVpc": "VPC",
    "redshiftVpcDesc": "指定您要将 Redshift 无服务器工作组部署到的 VPC。",
    "securityGroup": "安全组",
    "redshiftSecurityGroupDesc": "此 VPC 安全组定义了哪些子网和 IP 范围可以访问无服务器工作组。",
    "securityGroupPlaceholder": "选择安全组",
    "redshiftSubnet": "子网",
    "redshiftSubnetDesc": "请为 Redshift 无服务器选择三个子网。我们建议使用私有子网以提高安全性。",
    "redshiftDatabaseUser": "数据库用户",
    "redshiftDatabaseUserDesc": "该解决方案需要权限才能在 Redshift 集群中访问和创建数据库。默认情况下，它向 Redshift Data API 授予管理员用户执行创建数据库、表和视图以及加载数据的命令的权限。",
    "redshiftDatabaseUserPlaceholder": "database_admin_username",
    "athena": "Athena",
    "athenaDesc": "选择此选项将在 Athena 中创建表架构和示例查询，以便您在 S3 上查询已处理的数据",
    "certificate": "SSL 证书",
    "selectCertificate": "选择 SSL 证书",
    "accessPermissions": "访问权限",
    "accessPermissionsDesc": "该解决方案需要权限才能在 Redshift Serverless 中访问和创建数据库。创建或选择具有所需权限的身份和访问管理 (IAM) 角色。点击 “信息” 查看 ",
    "permissionLink": "在 Redshift 无服务器中成功创建数据库所需的权限",
    "findIAMRole": "查找 IAM 角色",
    "aga": " AWS 全球加速器",
    "agaDesc": "创建加速器以获取静态 IP 地址，这些地址充当您的采集服务器的全球固定入口点，这将提高您的采集服务器的可用性和性能。请注意，使用该服务会有额外费用产生。",
    "auth": "身份验证",
    "authDesc": "您可以使用 OpenID 连接器 (OIDC) 提供商对发送到您的采集服务器的请求进行身份验证。如果您打算启用它，请在 OIDC 提供商中创建一个 OIDC 客户端，然后在 AWS Secret Manager 中创建一个密钥，其中包含信息 “发行者”、“令牌终端节点”、“用户终端节点”、“授权终端节点”、“应用程序客户端 ID” 和 “应用程序客户端密钥”。",
    "enableALBLog": "访问日志",
    "enableALBLogDesc": "应用程序负载均衡器支持提供其收到的所有请求的详细日志。如果您启用此选项，则解决方案将自动为您启用访问日志，并将日志存储到您在上一步中选择的 S3 存储桶中。请注意，您需要向 S3 存储桶添加权限，ALB 才能传输日志。",
    "connector": "连接器",
    "connectorDesc": "创建 Apache Kafka 连接器以将数据流式传输到 S3。",
    "connectorCheck": "<guide_anchor>该解决方案将下载 Confluent <connector_anchor>Amazon S3 Sink连接器</connector_anchor>，然后按照本指南进行操作</guide_anchor>",
    "connectorCheckDesc": "允许解决方案为连接器创建自定义插件。",
    "securityWarning": "安全警告",
    "securityWarningDesc": "使用HTTP协议是不安全的，数据将在没有任何加密的情况下发送，在传输过程中存在数据泄露或被篡改的风险，请在继续操作之前确认风险。",
    "nextSteps": "接下来的步骤",
    "nextStepsDesc": "添加域名之后，请在域名系统 (DNS) 中创建别名(alias)或 CNAME 映射自定义域名到数据摄取端点地址。",
    "dataProcessing": "数据处理",
    "secret": "密钥",
    "selectSecret": "选择一个密钥",
    "createQSSub": "注册 QuickSight",
    "qsAccountName": "QuickSight 账户",
    "qsAccountNameDesc": "为您的 QuickSight 提供一个名称，请注意，此名称必须是全球唯一的。",
    "qsUserEmail": "QuickSight 用户",
    "qsUserEmailDesc": "为你的 QuickSight 提供一封电子邮件。",
    "createQSUser": "创建 QuickSigh",
    "qsCreateUserDesc": "提供一个链接供您激活用户和更改密码。",
    "qsUserActive": "点击下面的链接激活用户",
    "redshiftServerless": "无服务器",
    "redshiftServerlessDesc": "起始成本低，容量自动扩展，按使用量付费。",
    "redshiftProvisioned": "预置集群",
    "redshiftProvisionedDesc": "选择符合您的成本和性能规格的预置 Redshift 集群",
    "reportNotSupported": "不支持",
    "reportNotSupportedDesc": "如果未启用数据处理，则不支持自动生成分析报表。",
    "notSupportedServices": "以下服务：{{unSupportedServices}} 在此区域不可用，某些功能可能不支持。"
  },
  "detail": {
    "ingestion": "数据摄取",
    "processing": "数据处理和建模",
    "reporting": "报表",
    "monitoring": "监控",
    "alarms": "告警",
    "publicSubnet": "公共子网",
    "privateSubnet": "私有子网",
    "ingestionCapacity": "摄取容量",
    "enableHTTPS": "启用HTTPS",
    "domainName": "摄取端点域名",
    "dns": "DNS 记录值",
    "dnsInfo": "请在您的 DNS 里创建一个记录（Alias 或者 CNAME）指向该 DNS 记录值",
    "endpoint": "摄取端点 URL",
    "endpointInfo": "请配置 SDK 端将数据发送到此 URL",
    "acm": "SSL 证书",
    "enableAGA": "启用全球加速器",
    "enableAuth": "启用身份验证",
    "dataBuffer": "数据缓冲层",
    "topic": "topic",
    "enableALBLog": "启用 ALB 访问日志",
    "pipelineID": "数据管道 ID",
    "version": "版本",
    "s3Bucket": "Amazon S3 存储桶",
    "sdk": "数据收集 SDK",
    "cfnStack": "CloudFormation堆栈",
    "region": "区域",
    "vpc": "VPC",
    "creationTime": "创建时间",
    "updateTime": "更新时间",
    "min": "最小",
    "max": "最大",
    "warm": "Warm pool",
    "status": "状态",
    "dataProcessingInt": "数据处理间隔",
    "eventFreshness": "事件新鲜度",
    "transform": "转换",
    "enrichment": "富化",
    "analyticEngine": "分析引擎",
    "redshiftPermission": "Redshift 权限",
    "dataRange": "数据范围",
    "redshift": "Redshift",
    "athena": "Athena",
    "hours": "小时",
    "minutes": "分钟",
    "quicksightRole": "QuickSight 角色",
    "datasetName": "数据集名称",
    "accessFromConsole": "从 AWS 控制台访问 CloudWatch 中的监控面板。",
    "accessFromConsoleDesc": "该解决方案创建了一个 CloudWatch 监控面板，其中包含用于监控该数据管道的关键指标，点击上面的按钮即可在您的 AWS 控制台中访问控制面板。",
    "accessFromSolution": "访问解决方案控制台中的监控控制面板。",
    "accessFromSolutionDesc": "该解决方案创建了一个 CloudWatch 控制面板，其中包含用于监控该数据管道的关键指标，要将 CloudWatch 仪表板集成到解决方案控制台中，请按照以下步骤操作：",
    "accessFromSolutionStep1": "前往 CloudWatch 设置",
    "accessFromSolutionStep2": "为 CloudWatch 仪表板共享设置 SSO",
    "accessFromSolutionStep3": "转到为 CloudWatch 仪表板共享而创建的 Cognito 用户池，将 OIDC 控制平面提供商添加为联邦 OIDC",
    "accessFromSolutionStep4": "前往 CloudWatch 设置，选择联邦 OIDC 作为 SSO 提供商",
    "accessFromSolutionStep5": "前往 clickstream 管道控制面板，分享控制面板获取分享网址",
    "accessFromSolutionStep6": "在下面的输入框中提供共享网址，然后单击 “提交” 按钮。",
    "sharingUrl": "仪表板共享 URL",
    "alarmName": "告警名称",
    "alarmTable": "告警",
    "alarmTableDesc": "该项目管道的告警。",
    "alarmTableColumnName": "名称",
    "alarmTableColumnDesc": "描述",
    "alarmTableColumnState": "状态",
    "alarmTableColumnAction": "动作",
    "alarmTableLoading": "正在加载资源",
    "alarmTableNoAlarm": "没有告警",
    "alarmTableNoAlarmDisplay": "没有告警可显示。",
    "alarmFindAlarm": "找到你的告警",
    "alarmTableActionEnable": "启用",
    "alarmTableActionDisable": "不采取任何行动",
    "action": "行动",
    "stackDetails": "堆栈详情",
    "redshiftServerless": "Redshift 无服务器",
    "dashboards": "仪表板",
    "alarmDescription": "描述",
    "tags": "标签",
    "bufferSize": "缓冲区大小",
    "bufferInterval": "缓冲间隔",
    "analyticSchemaStatus": "Redshift Schemas"
  },
  "list": {
    "id": "管道 ID",
    "name": "管道名称",
    "region": "区域",
    "status": "状态",
    "created": "创建日期",
    "loading": "正在加载资源",
    "noPipeline": "没有管道",
    "noPipelineDisplay": "没有管道可供显示。",
    "findPipeline": "找到你的管道",
    "pipelineDesc": "您的 AWS 账户中的所有点击流分析数据管道。",
    "pipelineList": "数据管道清单"
  },
  "upgrade": {
    "title": "升级数据管道",
    "tip": "你确定要将数据管道升级到这个版本吗？",
    "needTimezone": "请先配置以下应用的报表时区，再进行管道升级。",
    "needTimezoneWarning": "请注意：应用程序的报表时区一旦确定，将无法更改。"
  }
}